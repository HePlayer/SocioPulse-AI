"""
SVRå¤„ç†å™¨
å¤„ç†å¹¶è¡ŒSVRç»“æœå¹¶åšå‡ºè®¨è®ºæµç¨‹å†³ç­–
"""

import asyncio
import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from .parallel_svr_engine import ParallelSVRResult, AgentSVRResult
from .discussion_context import DiscussionContext
from Item.Agentlib import Agent


class DiscussionAction(Enum):
    """å¯èƒ½çš„è®¨è®ºè¡ŒåŠ¨"""
    CONTINUE = "continue"
    STOP = "stop"
    PAUSE = "pause"
    REDIRECT = "redirect"
    SUMMARIZE = "summarize"


@dataclass
class SVRDecision:
    """SVRå¤„ç†å™¨åšå‡ºçš„å†³ç­–"""
    action: DiscussionAction
    selected_agent_id: Optional[str]
    selected_agent_name: Optional[str]
    confidence: float
    reasoning: List[str]
    metadata: Dict[str, Any]


class SVRHandler:
    """å¤„ç†SVRç»“æœå¹¶åšå‡ºè®¨è®ºæµç¨‹å†³ç­–"""
    
    def __init__(self,
                 stop_threshold: float = 0.8,
                 quality_threshold: float = 30.0):
        self.stop_threshold = stop_threshold
        self.quality_threshold = quality_threshold

        # ğŸ”§ å…³é”®ä¿®å¤ï¼šæ·»åŠ loggeråˆå§‹åŒ–ï¼Œè§£å†³AttributeError
        self.logger = logging.getLogger(f"{__name__}.SVRHandler")

        # å†³ç­–å†å²
        self.decision_history: List[SVRDecision] = []

        # ç®€åŒ–çš„è‡ªé€‚åº”é˜ˆå€¼ - ç§»é™¤consensusç›¸å…³
        self.adaptive_thresholds = {
            'stop_threshold': stop_threshold,
            'quality_threshold': quality_threshold
        }
        
        # æ€§èƒ½è·Ÿè¸ª
        self.decision_accuracy_history = []
    
    async def process_svr_results(self, 
                                 svr_result: ParallelSVRResult,
                                 context: DiscussionContext,
                                 participants: Dict[str, Agent]) -> SVRDecision:
        """
        å¤„ç†SVRç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        
        Args:
            svr_result: å¹¶è¡ŒSVRè®¡ç®—çš„ç»“æœ
            context: å½“å‰è®¨è®ºä¸Šä¸‹æ–‡
            participants: å¯ç”¨çš„Agent
            
        Returns:
            SVRDecision: å…³äºä¸‹ä¸€æ­¥è¡ŒåŠ¨çš„å†³ç­–
        """
        
        # æå–å…³é”®æŒ‡æ ‡
        global_metrics = svr_result.global_svr_metrics
        agent_results = svr_result.agent_results

        # åªä½¿ç”¨Så€¼å¹³å‡è¿›è¡Œå†³ç­–
        global_stop_average = global_metrics.get('global_stop_average', 0.0)
        discussion_quality = global_metrics.get('discussion_quality', 50.0)

        # ç®€åŒ–çš„å†³ç­–é€»è¾‘
        decision = await self._make_decision_simplified(
            global_stop_average, discussion_quality, agent_results, context, participants
        )
        
        # è®°å½•å†³ç­–
        self.decision_history.append(decision)
        if len(self.decision_history) > 100:  # ä¿ç•™æœ€è¿‘100ä¸ªå†³ç­–
            self.decision_history = self.decision_history[-100:]
        
        # æ›´æ–°è‡ªé€‚åº”é˜ˆå€¼
        await self._update_adaptive_thresholds(decision, svr_result)
        
        return decision
    
    async def _make_decision(self, 
                           global_stop: float,
                           consensus_level: float,
                           discussion_quality: float,
                           agent_results: Dict[str, AgentSVRResult],
                           context: DiscussionContext,
                           participants: Dict[str, Agent]) -> SVRDecision:
        """æ ¸å¿ƒå†³ç­–é€»è¾‘"""
        
        reasoning = []
        confidence = 0.8  # åŸºç¡€ç½®ä¿¡åº¦
        
        # æ£€æŸ¥åœæ­¢æ¡ä»¶ - ç§»é™¤å…±è¯†æ£€æŸ¥
        if global_stop >= self.adaptive_thresholds['stop_threshold']:
            reasoning.append(f"å…¨å±€åœæ­¢å€¼ ({global_stop:.2f}) è¶…è¿‡é˜ˆå€¼ ({self.adaptive_thresholds['stop_threshold']:.2f})")

            return SVRDecision(
                action=DiscussionAction.STOP,
                selected_agent_id=None,
                selected_agent_name=None,
                confidence=0.9,
                reasoning=reasoning,
                metadata={
                    'global_stop': global_stop,
                    'stop_reason': 'threshold_exceeded',
                    'decision_basis': 'legacy_stop_value'
                }
            )
        
        # ç§»é™¤åŸºäºè´¨é‡çš„å¹²é¢„æœºåˆ¶ - ä½¿ç”¨ç®€åŒ–çš„Vå€¼é€‰æ‹©
        # æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•å·²è¢«_make_decision_simplifiedæ›¿ä»£ï¼Œä½†ä¿æŒå…¼å®¹æ€§
        
        # ç»§ç»­è®¨è®º - é€‰æ‹©æœ€ä½³Agent
        selected_agent = await self._select_next_speaker(agent_results, context, participants)
        
        if selected_agent:
            reasoning.append(f"åŸºäºSVRåˆ†æé€‰æ‹© {selected_agent[1]}")
            reasoning.append(f"Agentç»¼åˆåˆ†æ•°: {agent_results[selected_agent[0]].svr_values.get('composite_score', 0):.1f}")
            
            return SVRDecision(
                action=DiscussionAction.CONTINUE,
                selected_agent_id=selected_agent[0],
                selected_agent_name=selected_agent[1],
                confidence=0.8,
                reasoning=reasoning,
                metadata={
                    'selection_method': 'svr_based',
                    'agent_svr_values': agent_results[selected_agent[0]].svr_values
                }
            )
        else:
            # åå¤‡ - æš‚åœè®¨è®º
            reasoning.append("æœªæ‰¾åˆ°åˆé€‚çš„Agentç»§ç»­")
            
            return SVRDecision(
                action=DiscussionAction.PAUSE,
                selected_agent_id=None,
                selected_agent_name=None,
                confidence=0.5,
                reasoning=reasoning,
                metadata={'pause_reason': 'no_suitable_agent'}
            )

    async def _make_decision_simplified(self,
                                      global_stop_average: float,
                                      discussion_quality: float,
                                      agent_results: Dict[str, AgentSVRResult],
                                      context: DiscussionContext,
                                      participants: Dict[str, Agent]) -> SVRDecision:
        """ç®€åŒ–çš„å†³ç­–é€»è¾‘ - åªåŸºäºSå€¼å¹³å‡"""

        reasoning = []
        confidence = 0.8

        # å”¯ä¸€çš„åœæ­¢æ¡ä»¶ï¼šSå€¼å¹³å‡è¶…è¿‡é˜ˆå€¼
        if global_stop_average >= self.adaptive_thresholds['stop_threshold']:
            reasoning.append(f"å…¨å±€åœæ­¢å¹³å‡å€¼ ({global_stop_average:.3f}) è¶…è¿‡é˜ˆå€¼ ({self.adaptive_thresholds['stop_threshold']:.3f})")

            return SVRDecision(
                action=DiscussionAction.STOP,
                selected_agent_id=None,
                selected_agent_name=None,
                confidence=0.9,
                reasoning=reasoning,
                metadata={
                    'global_stop_average': global_stop_average,
                    'stop_reason': 's_value_threshold_exceeded',
                    'decision_basis': 's_value_only'
                }
            )

        # ç§»é™¤è´¨é‡å¹²é¢„æœºåˆ¶ - ä¸å†åŸºäºdiscussion_qualityè¿›è¡Œå¹²é¢„
        # ç›´æ¥åŸºäºVå€¼é€‰æ‹©Agent
        selected_agent = await self._select_next_speaker(agent_results, context, participants)

        if selected_agent:
            reasoning.append(f"åŸºäºVå€¼é€‰æ‹© {selected_agent[1]}")
            reasoning.append(f"å…¨å±€åœæ­¢å¹³å‡å€¼: {global_stop_average:.3f} (ä½äºé˜ˆå€¼ {self.adaptive_thresholds['stop_threshold']:.3f})")

            # è·å–é€‰æ‹©çš„Agentçš„Vå€¼ç”¨äºè®°å½•
            selected_v_value = 0.0
            if agent_results and selected_agent[0] in agent_results:
                selected_v_value = agent_results[selected_agent[0]].svr_values.get('value_score', 0.0)

            return SVRDecision(
                action=DiscussionAction.CONTINUE,
                selected_agent_id=selected_agent[0],
                selected_agent_name=selected_agent[1],
                confidence=0.8,
                reasoning=reasoning,
                metadata={
                    'selection_method': 'highest_v_value',
                    'selected_v_value': selected_v_value,
                    'global_stop_average': global_stop_average,
                    'decision_basis': 'v_value_only'
                }
            )
        else:
            # åå¤‡ - æš‚åœè®¨è®º
            reasoning.append("æœªæ‰¾åˆ°åˆé€‚çš„Agentç»§ç»­")

            return SVRDecision(
                action=DiscussionAction.PAUSE,
                selected_agent_id=None,
                selected_agent_name=None,
                confidence=0.5,
                reasoning=reasoning,
                metadata={
                    'pause_reason': 'no_suitable_agent',
                    'global_stop_average': global_stop_average,
                    'decision_basis': 'v_value_selection_failed'
                }
            )

    async def _select_next_speaker(self,
                                  agent_results: Dict[str, AgentSVRResult],
                                  context: DiscussionContext,
                                  participants: Dict[str, Agent]) -> Optional[Tuple[str, str]]:
        """çº¯Vå€¼é€‰æ‹©æœºåˆ¶ï¼šé€‰æ‹©Vå€¼æœ€é«˜çš„Agent"""

        self.logger.info(f"å¼€å§‹åŸºäºVå€¼çš„Agenté€‰æ‹©:")
        self.logger.info(f"  agent_resultsæ•°é‡: {len(agent_results) if agent_results else 0}")
        self.logger.info(f"  participantsæ•°é‡: {len(participants)}")

        # å¦‚æœæ²¡æœ‰agent_resultsï¼Œä»æ‰€æœ‰participantsä¸­é€‰æ‹©ï¼ˆå†·å¯åŠ¨å¤„ç†ï¼‰
        if not agent_results:
            self.logger.info("agent_resultsä¸ºç©ºï¼Œä»æ‰€æœ‰participantsä¸­é€‰æ‹©ç¬¬ä¸€ä¸ªAgent")
            if participants:
                first_agent_id = list(participants.keys())[0]
                first_agent_name = participants[first_agent_id].name
                self.logger.info(f"âœ“ å†·å¯åŠ¨é€‰æ‹©: {first_agent_name} (ID: {first_agent_id})")
                return (first_agent_id, first_agent_name)
            else:
                self.logger.error("participantsä¹Ÿä¸ºç©ºï¼Œæ— æ³•é€‰æ‹©Agent")
                return None

        # æ”¶é›†æ‰€æœ‰Agentçš„Vå€¼
        agent_v_values = []

        for agent_id, result in agent_results.items():
            if agent_id in participants:
                v_value = result.svr_values.get('value_score', 0.0)
                agent_name = participants[agent_id].name
                agent_v_values.append((agent_id, agent_name, v_value))
                self.logger.debug(f"  Agent {agent_name} (ID: {agent_id}): Vå€¼={v_value:.1f}")
            else:
                self.logger.warning(f"  è·³è¿‡Agent {agent_id}: ä¸åœ¨participantsä¸­")

        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„Agentï¼Œä»participantsä¸­é€‰æ‹©
        if not agent_v_values:
            self.logger.warning("æ²¡æœ‰åŒ¹é…çš„Agentï¼Œä»participantsä¸­é€‰æ‹©ç¬¬ä¸€ä¸ª")
            if participants:
                first_agent_id = list(participants.keys())[0]
                first_agent_name = participants[first_agent_id].name
                self.logger.info(f"âœ“ åå¤‡é€‰æ‹©: {first_agent_name} (ID: {first_agent_id})")
                return (first_agent_id, first_agent_name)
            else:
                self.logger.error("participantsä¸ºç©ºï¼Œæ— æ³•é€‰æ‹©Agent")
                return None

        # æŒ‰Vå€¼æ’åºï¼ˆé™åºï¼‰
        agent_v_values.sort(key=lambda x: x[2], reverse=True)

        # è®°å½•æ’åºç»“æœ
        self.logger.info(f"Vå€¼æ’åºç»“æœ:")
        for i, (agent_id, agent_name, v_value) in enumerate(agent_v_values[:3]):  # æ˜¾ç¤ºå‰3å
            self.logger.info(f"  {i+1}. {agent_name}: Vå€¼={v_value:.1f}")

        # é€‰æ‹©Vå€¼æœ€é«˜çš„Agent
        selected_agent_id, selected_agent_name, highest_v_value = agent_v_values[0]

        self.logger.info(f"âœ“ é€‰æ‹©Vå€¼æœ€é«˜çš„Agent: {selected_agent_name} (Vå€¼: {highest_v_value:.1f})")

        # éªŒè¯é€‰æ‹©çš„Agentåœ¨participantsä¸­
        if selected_agent_id in participants:
            self.logger.debug(f"  éªŒè¯é€šè¿‡: Agent {selected_agent_id} åœ¨participantsä¸­")
            return (selected_agent_id, selected_agent_name)
        else:
            self.logger.error(f"  éªŒè¯å¤±è´¥: Agent {selected_agent_id} ä¸åœ¨participantsä¸­")
            return None
    
    # ğŸš« ç§»é™¤è´¨é‡å¹²é¢„æœºåˆ¶ - ä¸å†éœ€è¦_select_quality_improveræ–¹æ³•
    # async def _select_quality_improver(self, agent_results, participants):
    #     """ä¸å†éœ€è¦è´¨é‡å¹²é¢„æœºåˆ¶"""
    #     pass

    # ğŸš« ç§»é™¤å¢é‡é€‰æ‹©æœºåˆ¶ - ä¸å†éœ€è¦_select_next_speaker_deltaæ–¹æ³•
    # async def _select_next_speaker_delta(self, agent_results, context, participants):
    #     """ä¸å†éœ€è¦å¢é‡é€‰æ‹©æœºåˆ¶"""
    #     pass

    # ğŸš« ç§»é™¤å¤šæ ·æ€§æ£€æŸ¥æœºåˆ¶ - ä¸å†éœ€è¦_get_recent_speakersæ–¹æ³•
    # async def _get_recent_speakers(self, context, count):
    #     """ä¸å†éœ€è¦å¤šæ ·æ€§æ£€æŸ¥"""
    #     pass
    
    async def _update_adaptive_thresholds(self, decision: SVRDecision, svr_result: ParallelSVRResult):
        """åŸºäºå†³ç­–ç»“æœæ›´æ–°è‡ªé€‚åº”é˜ˆå€¼"""
        
        # ç®€å•è‡ªé€‚åº”æœºåˆ¶ - å¯ä»¥ç”¨æœºå™¨å­¦ä¹ å¢å¼º
        global_metrics = svr_result.global_svr_metrics
        
        # å¦‚æœæˆ‘ä»¬ä¸€ç›´åœæ­¢å¾—å¤ªæ—©æˆ–å¤ªæ™šï¼Œè°ƒæ•´é˜ˆå€¼
        if len(self.decision_history) >= 10:
            recent_decisions = self.decision_history[-10:]
            stop_decisions = [d for d in recent_decisions if d.action == DiscussionAction.STOP]
            
            # å¦‚æœåœæ­¢å¤ªé¢‘ç¹ï¼Œå¢åŠ åœæ­¢é˜ˆå€¼
            if len(stop_decisions) > 7:  # è¶…è¿‡70%çš„åœæ­¢å†³ç­–
                self.adaptive_thresholds['stop_threshold'] = min(0.95, self.adaptive_thresholds['stop_threshold'] + 0.05)
            
            # å¦‚æœåœæ­¢ä¸å¤Ÿï¼Œé™ä½åœæ­¢é˜ˆå€¼
            elif len(stop_decisions) < 2:  # å°‘äº20%çš„åœæ­¢å†³ç­–
                self.adaptive_thresholds['stop_threshold'] = max(0.6, self.adaptive_thresholds['stop_threshold'] - 0.05)
        
        # åŸºäºè®¨è®ºç»“æœè°ƒæ•´è´¨é‡é˜ˆå€¼
        discussion_quality = global_metrics.get('discussion_quality', 50.0)
        if discussion_quality < 20:  # è´¨é‡å¾ˆä½
            self.adaptive_thresholds['quality_threshold'] = min(40, self.adaptive_thresholds['quality_threshold'] + 5)
        elif discussion_quality > 80:  # è´¨é‡é«˜
            self.adaptive_thresholds['quality_threshold'] = max(20, self.adaptive_thresholds['quality_threshold'] - 2)
    
    def get_decision_statistics(self) -> Dict[str, Any]:
        """è·å–å†³ç­–åˆ¶å®šçš„ç»Ÿè®¡ä¿¡æ¯"""
        if not self.decision_history:
            return {'total_decisions': 0}
        
        action_counts = {}
        for decision in self.decision_history:
            action = decision.action.value
            action_counts[action] = action_counts.get(action, 0) + 1
        
        avg_confidence = sum(d.confidence for d in self.decision_history) / len(self.decision_history)
        
        return {
            'total_decisions': len(self.decision_history),
            'action_distribution': action_counts,
            'average_confidence': avg_confidence,
            'current_thresholds': self.adaptive_thresholds.copy(),
            'recent_decisions': [
                {
                    'action': d.action.value,
                    'confidence': d.confidence,
                    'selected_agent': d.selected_agent_name
                }
                for d in self.decision_history[-5:]
            ]
        }
